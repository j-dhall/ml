{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"orange\">Gaussian Naive Bayes for MNIST Digits Classification</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math #to check for nan\n",
    "import numpy as np\n",
    "from numpy import mean, std #mean and standard deviation for gaussian probabilities\n",
    "from scipy.stats import norm #gaussian probabilities\n",
    "from math import log # to calculate posterior probability\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt #display images of digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load mnist data from Tensorflow Keras library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check for data getting loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(60000, 28, 28), (60000,), (10000, 28, 28), (10000,)]\n",
      "[<class 'numpy.ndarray'>, <class 'numpy.ndarray'>, <class 'numpy.ndarray'>, <class 'numpy.ndarray'>]\n",
      "classes, num_classes:  [0 1 2 3 4 5 6 7 8 9] 10\n"
     ]
    }
   ],
   "source": [
    "print([i.shape for i in (x_train, y_train, x_test, y_test)])\n",
    "print([type(i) for i in (x_train, y_train, x_test, y_test)])\n",
    "print('classes, num_classes: ', np.unique(y_train), len(np.unique(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    return\n",
    "            classes: (list) of unique class names in the dataset,\n",
    "             got from the last column named class_colname.\n",
    "             \n",
    "            features: (list) of features (column names) in the dataset.\n",
    "             this excludes the last column which we expect it to have the class labels.\n",
    "             \n",
    "            prior: (1-d array) of dim num_classes\n",
    "            (prior probability of a set of features belonging to a class)\n",
    "            \n",
    "            mean_std: (3-d array) of dim num_classes x num_features x 2 (2: mean and std)\n",
    "            (mean and standard deviation for all features, given the class)\n",
    "            \n",
    "    arguments:\n",
    "    df: (dataframe) with features and class names (should have a 'class' column in addition to the feature columns).\n",
    "    class_colname: (string) provide suitable column name otherwise, using the class_colname argument.\n",
    "'''\n",
    "def train_gaussian_nb(X, y):\n",
    "    #number of classes\n",
    "    classes = np.unique(y)\n",
    "    num_classes = len(classes)\n",
    "    #number of data points and features\n",
    "    N, dim_x, dim_y = X.shape[0], X.shape[1], X.shape[2]\n",
    "    \n",
    "    #data structures for priors and\n",
    "    # (mean, standard deviation) pairs for each feature and class\n",
    "    # to later calculate likelihood (conditional probability of feature given class)\n",
    "    prior = np.zeros(num_classes, dtype=float)\n",
    "    X_mean = np.empty((num_classes, dim_x, dim_y), dtype=float)\n",
    "    X_std = np.empty((num_classes, dim_x, dim_y), dtype=float)\n",
    "    \n",
    "    #for each class...\n",
    "    for cls in range(num_classes):\n",
    "        #use a boolean index list to extract images of this class\n",
    "        bool_idx_list = [True if c==cls else False for c in y]\n",
    "        X_cls = X[bool_idx_list]\n",
    "        \n",
    "        #calculate prior probability of data point belonging to class cls\n",
    "        prior[cls] = len(X_cls) / N\n",
    "\n",
    "        #for each dim_x by dim_y, calculate mean and std, across all data points of this class\n",
    "        X_mean[cls] = mean(X_cls, axis=0)\n",
    "        X_std[cls] = std(X_cls, axis=0)\n",
    "            \n",
    "    return classes, dim_x, dim_y, prior, X_mean, X_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### original straightforward approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    return (integer) the (0-based) index of class to which the document belongs\n",
    "    \n",
    "    arguments:\n",
    "    num_classes: (int) number of classes\n",
    "    num_features: (int) number of features\n",
    "    prior: (1-d array) of dim num_classes\n",
    "           (prior probability of a set of features belonging to a class)\n",
    "    mean_std: (3-d array) of dim num_classes x num_features x 2 (2: mean and std)\n",
    "              (mean and standard deviation for all features, given the class)\n",
    "    x: (list) of features\n",
    "'''\n",
    "def apply_gaussian_naive_bayes(num_classes, dim_x, dim_y, prior, X_mean, X_std, x):\n",
    "    score = np.zeros((num_classes), dtype=float)\n",
    "    \n",
    "    #for each class...\n",
    "    for cls in range(num_classes):\n",
    "        \n",
    "        #for this class, add the log-prior probability to the score\n",
    "        score[cls] += log(prior[cls], 10) #log to the base 10\n",
    "        \n",
    "        #for each feature, add the log-likelihood to the score\n",
    "        for i_x in range(dim_x):\n",
    "            for i_y in range(dim_y):\n",
    "                #calculate likelihood from the trained mean and standard deviation\n",
    "                mu = X_mean[cls][i_x][i_y]\n",
    "                sigma = X_std[cls][i_x][i_y]\n",
    "                likelihood = norm(mu, sigma).pdf(x[i_x][i_y])\n",
    "                #print(mu, sigma, x[i_x][i_y], likelihood)\n",
    "\n",
    "                #add the log-likelihood to the score\n",
    "                \n",
    "                #ValueError exception raised if likelihood is 0 and we take a log.\n",
    "                #To avoid this, we skip adding log_likelihood to the score.\n",
    "                #We may argue that score should be penalized for\n",
    "                # such a great mismatch of pixel intensity for a class,\n",
    "                # but, these pixels are more of a candidate of noise, and can be ignored.\n",
    "                #Also, skip NaN values for likelihood (when mu and sigma are 0 and so is x)\n",
    "                if (math.isnan(likelihood) == True or likelihood == 0):\n",
    "                    continue\n",
    "                \n",
    "                #print(likelihood)\n",
    "                score[cls] += log(likelihood, 10) #log to the base 10\n",
    "\n",
    "    #return the index of class with the maximum-a-posterior probability\n",
    "    return score.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### applying function on dim_x x dim_y matrix approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I thought applying function axis-wise will run faster. But, it <font color=\"red\">takes about the same time</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    return (float) log-likelihood for a pixel in a data-point\n",
    "    \n",
    "    description: for a class, this function is called dim_x by dim_y times, once for each pixel.\n",
    "    \n",
    "    arguments:\n",
    "    a: (array of dim 3) an array having mu, sigma, and a pixel of x\n",
    "'''\n",
    "def f_norm(a):\n",
    "    #very important to keep it float.\n",
    "    #a difference of ~300 was observed (e.g. score|class = -1400 instead of -1700)\n",
    "    # if log_like was = 0 (int) instead of 0.0 (float)\n",
    "    # looks like something to do with log_like = log(likelihood, 10)\n",
    "    log_like = 0.0\n",
    "\n",
    "    #a[0] has mu, a[1] has sigma, and a[2]has a pixel of x\n",
    "    likelihood =  norm(a[0], a[1]).pdf(a[2])\n",
    "    if (math.isnan(likelihood) == True or likelihood == 0):\n",
    "        return log_like\n",
    "    \n",
    "    #print(likelihood)\n",
    "    log_like = log(likelihood, 10) #log to the base 10\n",
    "    \n",
    "    return log_like\n",
    "\n",
    "'''\n",
    "    return (integer) the (0-based) index of class to which the document belongs\n",
    "    \n",
    "    arguments:\n",
    "    num_classes: (int) number of classes\n",
    "    num_features: (int) number of features\n",
    "    prior: (1-d array) of dim num_classes\n",
    "           (prior probability of a set of features belonging to a class)\n",
    "    mean_std: (3-d array) of dim num_classes x num_features x 2 (2: mean and std)\n",
    "              (mean and standard deviation for all features, given the class)\n",
    "    x: (list) of features\n",
    "'''\n",
    "def apply_gaussian_naive_bayes_fast(num_classes, dim_x, dim_y, prior, X_mean, X_std, x):\n",
    "    score = np.zeros((num_classes), dtype=float)\n",
    "    \n",
    "    #for each class...\n",
    "    for cls in range(num_classes):\n",
    "        \n",
    "        #for this class, add the log-prior probability to the score\n",
    "        score[cls] += log(prior[cls], 10) #log to the base 10\n",
    "        \n",
    "        norm_matrices = np.empty((3, dim_x, dim_y), dtype=float)\n",
    "        norm_matrices[0] = X_mean[cls]\n",
    "        norm_matrices[1] =  X_std[cls]\n",
    "        norm_matrices[2] = x\n",
    "        \n",
    "        log_like_x_y = np.apply_along_axis(f_norm, 0, norm_matrices)\n",
    "        \n",
    "        score[cls] += np.sum(log_like_x_y)\n",
    "\n",
    "    #return the index of class with the maximum-a-posterior probability\n",
    "    return score.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the prior and likelihood on observed data (x_train, y_train)\n",
    "classes, dim_x, dim_y, prior, X_mean, X_std = train_gaussian_nb(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check the trained mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09871667, 0.11236667, 0.0993    , 0.10218333, 0.09736667,\n",
       "       0.09035   , 0.09863333, 0.10441667, 0.09751667, 0.09915   ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23cbb9b0388>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_mean[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23cbba53e48>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_std[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### time performance comparison of apply_gaussian_naive_bayes with apply_gaussian_naive_bayes<font color=\"magenta\">_fast</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeete\\.conda\\envs\\Python37Env\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1760: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n",
      "C:\\Users\\jeete\\.conda\\envs\\Python37Env\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1760: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.773550033569336\n",
      "6.2529566287994385\n",
      "7\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "pred_cls = apply_gaussian_naive_bayes(len(classes), dim_x, dim_y, prior, X_mean, X_std, x_test[0])\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "start = time.time()\n",
    "pred_cls_fast = apply_gaussian_naive_bayes_fast(len(classes), dim_x, dim_y, prior, X_mean, X_std, x_test[0])\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "print(pred_cls)\n",
    "print(pred_cls_fast)\n",
    "\n",
    "#output\n",
    "#6.216400146484375\n",
    "#6.311165809631348\n",
    "#7\n",
    "#7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(predicted, actual): 7 7\n",
      "(predicted, actual): 2 2\n",
      "(predicted, actual): 1 1\n",
      "(predicted, actual): 0 0\n",
      "(predicted, actual): 9 4\n",
      "(predicted, actual): 1 1\n",
      "(predicted, actual): 8 4\n",
      "(predicted, actual): 9 9\n",
      "(predicted, actual): 4 5\n",
      "(predicted, actual): 9 9\n",
      "(predicted, actual): 0 0\n",
      "(predicted, actual): 6 6\n",
      "(predicted, actual): 9 9\n",
      "(predicted, actual): 0 0\n",
      "(predicted, actual): 1 1\n",
      "(predicted, actual): 0 5\n",
      "(predicted, actual): 9 9\n",
      "(predicted, actual): 7 7\n",
      "(predicted, actual): 2 3\n",
      "(predicted, actual): 9 4\n",
      "(predicted, actual): 9 9\n",
      "(predicted, actual): 6 6\n",
      "(predicted, actual): 6 6\n",
      "(predicted, actual): 8 5\n",
      "(predicted, actual): 9 4\n",
      "(predicted, actual): 0 0\n",
      "(predicted, actual): 9 7\n",
      "(predicted, actual): 9 4\n",
      "(predicted, actual): 0 0\n",
      "(predicted, actual): 1 1\n",
      "(predicted, actual): 9 3\n",
      "(predicted, actual): 1 1\n",
      "(predicted, actual): 3 3\n",
      "(predicted, actual): 0 4\n",
      "(predicted, actual): 7 7\n",
      "(predicted, actual): 0 2\n",
      "(predicted, actual): 7 7\n",
      "(predicted, actual): 1 1\n",
      "(predicted, actual): 8 2\n",
      "(predicted, actual): 1 1\n",
      "(predicted, actual): 1 1\n",
      "(predicted, actual): 9 7\n",
      "(predicted, actual): 9 4\n",
      "(predicted, actual): 6 2\n",
      "(predicted, actual): 3 3\n",
      "(predicted, actual): 8 5\n",
      "(predicted, actual): 8 1\n",
      "(predicted, actual): 6 2\n",
      "(predicted, actual): 9 4\n",
      "(predicted, actual): 4 4\n",
      "(predicted, actual): 6 6\n",
      "(predicted, actual): 3 3\n",
      "(predicted, actual): 8 5\n",
      "(predicted, actual): 0 5\n",
      "(predicted, actual): 6 6\n",
      "(predicted, actual): 0 0\n",
      "(predicted, actual): 4 4\n",
      "(predicted, actual): 1 1\n",
      "(predicted, actual): 9 9\n",
      "(predicted, actual): 8 5\n",
      "(predicted, actual): 7 7\n",
      "(predicted, actual): 8 8\n",
      "(predicted, actual): 9 9\n",
      "(predicted, actual): 3 3\n",
      "(predicted, actual): 7 7\n",
      "(predicted, actual): 1 4\n",
      "(predicted, actual): 6 6\n",
      "(predicted, actual): 4 4\n",
      "(predicted, actual): 8 3\n",
      "(predicted, actual): 0 0\n",
      "(predicted, actual): 7 7\n",
      "(predicted, actual): 0 0\n",
      "(predicted, actual): 3 2\n",
      "(predicted, actual): 9 9\n",
      "(predicted, actual): 1 1\n",
      "(predicted, actual): 7 7\n",
      "(predicted, actual): 3 3\n",
      "(predicted, actual): 2 2\n",
      "(predicted, actual): 9 9\n",
      "(predicted, actual): 7 7\n",
      "(predicted, actual): 9 7\n",
      "(predicted, actual): 6 6\n",
      "(predicted, actual): 2 2\n",
      "(predicted, actual): 9 7\n",
      "(predicted, actual): 8 8\n",
      "(predicted, actual): 4 4\n",
      "(predicted, actual): 9 7\n",
      "(predicted, actual): 3 3\n",
      "(predicted, actual): 6 6\n",
      "(predicted, actual): 1 1\n",
      "(predicted, actual): 3 3\n",
      "(predicted, actual): 6 6\n",
      "(predicted, actual): 9 9\n",
      "(predicted, actual): 8 3\n",
      "(predicted, actual): 1 1\n",
      "(predicted, actual): 4 4\n",
      "(predicted, actual): 1 1\n",
      "(predicted, actual): 4 7\n",
      "(predicted, actual): 6 6\n",
      "(predicted, actual): 9 9\n",
      "Correct:  68 Incorrect:  32\n",
      "Percentage of correct predictions:  68.0\n"
     ]
    }
   ],
   "source": [
    "#iterate over test dataset and count the number of correct and incorrect predictions\n",
    "count_correct, count_incorrect = 0, 0\n",
    "#since each prediction is taking ~6 seconds, we can predict 10 digits per minute.\n",
    "#allowing the classification to run for 10 minutes, we will have 100 predictions.\n",
    "#so, setting the range as 0..100\n",
    "for i in range(100): #len(x_test)):\n",
    "    #actual class\n",
    "    actual_cls = y_test[i]\n",
    "    #predicted class\n",
    "    # input provided as row[:-1].to_list(), means, all columns except last, converted to a list\n",
    "    pred_cls = apply_gaussian_naive_bayes(len(classes), dim_x, dim_y, prior, X_mean, X_std, x_test[i])\n",
    "    if classes[pred_cls] == actual_cls:\n",
    "        count_correct += 1\n",
    "    else:\n",
    "        count_incorrect += 1\n",
    "    print('(predicted, actual):', pred_cls, actual_cls)\n",
    "print('Correct: ', count_correct, 'Incorrect: ', count_incorrect)\n",
    "print('Percentage of correct predictions: ', (count_correct * 100)/(count_correct + count_incorrect))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
