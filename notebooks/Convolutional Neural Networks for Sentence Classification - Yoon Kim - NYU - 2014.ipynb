{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #data cleaning\n",
    "import string #\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers.experimental.preprocessing\\\n",
    "import TextVectorization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.initializers import Constant\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_train = '..\\\\input\\\\movie-review-sentiment-analysis-kernels-only\\\\train.tsv'\n",
    "data_file_test = '..\\\\input\\\\movie-review-sentiment-analysis-kernels-only\\\\test.tsv'\n",
    "embed_file_glove = '..\\\\input\\\\glove-global-vectors-for-word-representation\\\\glove.6B.200d.txt'\n",
    "embed_file_word2vec = '..\\\\input\\\\GoogleNews-vectors-negative300.bin\\\\GoogleNews-vectors-negative300.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 300 #this has to match the embed_file we choose above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read the data files into data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "df_train = pd.read_csv(data_file_train, delimiter='\\t')\n",
    "df_test = pd.read_csv(data_file_test, delimiter='\\t') #for submission\n",
    "print('***Training Set:***\\n', df_train.head(1))\n",
    "print('***Testing Set:***\\n', df_test.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unwanted columns\n",
    "def retain_cols(df, cols):\n",
    "    df = df[cols]\n",
    "    return df\n",
    "\n",
    "#Turn url's into url, remove anything that's not alphanumeric or a space.\n",
    "#Then lowercase what's left.\n",
    "def clean_str(in_str):\n",
    "    in_str = str(in_str)\n",
    "    # replace urls with 'url'\n",
    "    in_str = re.sub(r\"(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]\\\n",
    "    [a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]\\\n",
    "    [a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}\\\n",
    "    |https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]\\\n",
    "    \\.[^\\s]{2,}|www\\.[a-zA-Z0-9]\\.[^\\s]{2,})\",\\\n",
    "                    \"url\", in_str)\n",
    "    in_str = re.sub(r'([^\\s\\w]|_)+', '', in_str)\n",
    "    return in_str.strip().lower()\n",
    "\n",
    "#clean the data\n",
    "def clean_data(df, cols):\n",
    "    df = retain_cols(df, cols)\n",
    "    df['Text'] = df['Phrase'].apply(clean_str)\n",
    "    return df\n",
    "\n",
    "df_train = clean_data(df_train, ['Phrase', 'Sentiment'])\n",
    "df_test = clean_data(df_test, ['Phrase']) #for submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### balancing classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is classified into 5 different classes, very negative, slightly negative, neutral, slightly positive and very positive.\n",
    "\n",
    "Sadly our dataset isn't balanced, so we need to do that ourselves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: <font color='orange'>using alias 'df' for 'df_train'</font> for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df[df['Sentiment'] == 0].sample(frac=1)\n",
    "df_1 = df[df['Sentiment'] == 1].sample(frac=1)\n",
    "df_2 = df[df['Sentiment'] == 2].sample(frac=1)\n",
    "df_3 = df[df['Sentiment'] == 3].sample(frac=1)\n",
    "df_4 = df[df['Sentiment'] == 4].sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want a balanced set for training against - there are 7072 `0` examples\n",
    "sample_size = 7072\n",
    "\n",
    "data = pd.concat([df_0.head(sample_size),\\\n",
    "                  df_1.head(sample_size),\\\n",
    "                  df_2.head(sample_size),\\\n",
    "                  df_3.head(sample_size),\\\n",
    "                  df_4.head(sample_size)]).sample(frac=1)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: <font color='orange'>'data' represents 'df_train' after data preprocessing</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### input vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sequence length and max features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['l'] = data['Text'].apply(lambda x: len(str(x).split(' ')))\n",
    "print(\"mean length of sentence: \" + str(data.l.mean()))\n",
    "print(\"max length of sentence: \" + str(data.l.max()))\n",
    "print(\"std dev length of sentence: \" + str(data.l.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these sentences aren't that long so we may as well use the whole string\n",
    "sequence_length = int(data.l.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000 # this is the number of words we care about"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TextVectorization(max_tokens=max_features,\\\n",
    "                               output_sequence_length=sequence_length)\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(data['Text'].values).batch(128)\n",
    "vectorizer.adapt(text_ds)\n",
    "voc = vectorizer.get_vocabulary()\n",
    "print('Vocabulary:', voc[:5])\n",
    "print('Vectorizing \"the cat sat on the mat\":\\n',\\\n",
    "     vectorizer([[\"the cat sat on the mat\"]]).numpy()[0, :6])\n",
    "word_index = dict(zip([x.decode('utf-8') for x in voc], range(len(voc))))\n",
    "print('Word index of words [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]:', \\\n",
    "      [word_index[w] for w in [\"the\", \"cat\", \"sat\", \"on\", \"the\"]])#, \"mat\"\n",
    "#'mat' is not in the vocabulary.\n",
    "#hence, vocabulary index is 1 (index 0 for empty token)\n",
    "#(index 2 onwards for words in vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: The index of vectorizing is off by 2 when compared with word index generated from its vocabulary. We will have to <font color='blue'>make adjustment of 2 when creating the embedding matrix.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### vectorize input and split for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer(np.array([[s] for s in data['Text'].values])).numpy()\n",
    "y = np.array(pd.get_dummies(data['Sentiment']).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where there isn't a test set, Kim keeps back 10% of the data for testing,\n",
    "#I'm going to do the same since we have an ok amount to play with\n",
    "X_train, X_val, y_train, y_val =\\\n",
    "train_test_split(X, y, test_size=0.1)\n",
    "print(\"Validation set size \" + str(len(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load GloVe embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embeddings_index = {}\n",
    "f_embed = open(embed_file_glove, encoding=\"utf8\")\n",
    "for line in f_embed:\n",
    "    tokens = line.split()\n",
    "    word = tokens[0]\n",
    "    coefs = np.asarray(tokens[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f_embed.close()\n",
    "print('Found %s word vectors' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec = KeyedVectors.load_word2vec_format(embed_file_word2vec, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = min(max_features, len(word_index)) + 2\n",
    "embedding_dim = embed_dim\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    try:\n",
    "        embedding_vector = embeddings_index[word]\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            # This includes the representation for \"padding\" and \"OOV\"\n",
    "            embedding_matrix[i+2] = embedding_vector\n",
    "            hits += 1\n",
    "        else:#for non-exception throwing embeddings_index\n",
    "            misses += 1\n",
    "    except KeyError: #for non-exception throwing embeddings_index\n",
    "        misses += 1\n",
    "        continue\n",
    "\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - CNN for Sentence Classification - Yoon Kim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/hamishdickson/cnn-for-sentence-classification-by-yoon-kim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filters = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_3 = Input(shape=(sequence_length,), dtype='int32')\n",
    "embedding_layer_3 = Embedding(num_words,\n",
    "                            embedding_dim,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=sequence_length,\n",
    "                            trainable=True)(inputs_3)\n",
    "\n",
    "reshape_3 = Reshape((sequence_length, embedding_dim, 1))(embedding_layer_3)\n",
    "\n",
    "# note the relu activation\n",
    "conv_0_3 = Conv2D(num_filters, kernel_size=(3, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(reshape_3)\n",
    "conv_1_3 = Conv2D(num_filters, kernel_size=(4, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(reshape_3)\n",
    "conv_2_3 = Conv2D(num_filters, kernel_size=(5, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(reshape_3)\n",
    "\n",
    "maxpool_0_3 = MaxPool2D(pool_size=(sequence_length - 3 + 1, 1), strides=(1,1), padding='valid')(conv_0_3)\n",
    "maxpool_1_3 = MaxPool2D(pool_size=(sequence_length - 4 + 1, 1), strides=(1,1), padding='valid')(conv_1_3)\n",
    "maxpool_2_3 = MaxPool2D(pool_size=(sequence_length - 5 + 1, 1), strides=(1,1), padding='valid')(conv_2_3)\n",
    "\n",
    "concatenated_tensor_3 = Concatenate(axis=1)([maxpool_0_3, maxpool_1_3, maxpool_2_3])\n",
    "flatten_3 = Flatten()(concatenated_tensor_3)\n",
    "\n",
    "dropout_3 = Dropout(0.5)(flatten_3)\n",
    "output_3 = Dense(units=5, activation='softmax')(dropout_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = Model(inputs=inputs_3, outputs=output_3)\n",
    "model_3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model_3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "history_3 = model_3.fit(X_train, y_train,\\\n",
    "                        epochs=20, batch_size=batch_size,\\\n",
    "                        verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot training and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_3.history['accuracy'])\n",
    "plt.plot(history_3.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history_3.history['loss'])\n",
    "plt.plot(history_3.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_3 = model_3.predict(X_val)\n",
    "accuracy_score(list(map(lambda x: np.argmax(x), y_val)),\\\n",
    "               list(map(lambda x: np.argmax(x), y_hat_3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(list(map(lambda x: np.argmax(x), y_val)),\\\n",
    "                 list(map(lambda x: np.argmax(x), y_hat_3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer(np.array([[s] for s in ['amazing', 'thrilling experience', 'expected more', 'it was fun', 'waste of time']])).numpy()\n",
    "y_test = model_3.predict(X_test)\n",
    "[(i+1, list(y).index(max(y))) for i, y in enumerate(y_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer(np.array([[s] for s in df_test['Text'].values])).numpy()\n",
    "y_test = model_3.predict(X_test)\n",
    "y_test_class = [list(y).index(max(y)) for i, y in enumerate(y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_sub = '..\\\\input\\\\movie-review-sentiment-analysis-kernels-only\\\\sampleSubmission.csv'\n",
    "df_sub = pd.read_csv(data_file_sub)\n",
    "df_sub['Sentiment'] = np.asarray(y_test_class)\n",
    "df_sub.to_csv(\"cnn.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model - Bidirectional GRU and LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/artgor/movie-review-sentiment-analysis-eda-and-models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, \\\n",
    "Callback, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout,\\\n",
    "Activation, Conv1D, GRU, GRU, LSTM, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model, load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = sequence_length\n",
    "embed_size = embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model1(lr=0.0, lr_d=0.0, units=0, spatial_dr=0.0, kernel_size1=3, kernel_size2=2, dense_units=128, dr=0.1, conv_size=32):\n",
    "    file_path = \"best_model.hdf5\"\n",
    "    check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
    "                                  save_best_only = True, mode = \"min\")\n",
    "    early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 3)\n",
    "    \n",
    "    inp = Input(shape = (max_len,))\n",
    "    x = Embedding(num_words, embed_size, weights = [embedding_matrix], trainable = False)(inp)\n",
    "    x1 = SpatialDropout1D(spatial_dr)(x)\n",
    "\n",
    "    x_gru = Bidirectional(GRU(units, return_sequences = True))(x1)\n",
    "    x1 = Conv1D(conv_size, kernel_size=kernel_size1, padding='valid', kernel_initializer='he_uniform')(x_gru)\n",
    "    avg_pool1_gru = GlobalAveragePooling1D()(x1)\n",
    "    max_pool1_gru = GlobalMaxPooling1D()(x1)\n",
    "    \n",
    "    x3 = Conv1D(conv_size, kernel_size=kernel_size2, padding='valid', kernel_initializer='he_uniform')(x_gru)\n",
    "    avg_pool3_gru = GlobalAveragePooling1D()(x3)\n",
    "    max_pool3_gru = GlobalMaxPooling1D()(x3)\n",
    "    \n",
    "    x_lstm = Bidirectional(LSTM(units, return_sequences = True))(x1)\n",
    "    x1 = Conv1D(conv_size, kernel_size=kernel_size1, padding='valid', kernel_initializer='he_uniform')(x_lstm)\n",
    "    avg_pool1_lstm = GlobalAveragePooling1D()(x1)\n",
    "    max_pool1_lstm = GlobalMaxPooling1D()(x1)\n",
    "    \n",
    "    x3 = Conv1D(conv_size, kernel_size=kernel_size2, padding='valid', kernel_initializer='he_uniform')(x_lstm)\n",
    "    avg_pool3_lstm = GlobalAveragePooling1D()(x3)\n",
    "    max_pool3_lstm = GlobalMaxPooling1D()(x3)\n",
    "    \n",
    "    \n",
    "    x = concatenate([avg_pool1_gru, max_pool1_gru, avg_pool3_gru, max_pool3_gru,\n",
    "                    avg_pool1_lstm, max_pool1_lstm, avg_pool3_lstm, max_pool3_lstm])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dr)(Dense(dense_units, activation='relu') (x))\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dr)(Dense(int(dense_units / 2), activation='relu') (x))\n",
    "    x = Dense(5, activation = \"sigmoid\")(x)\n",
    "    model = Model(inputs = inp, outputs = x)\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n",
    "    history = model.fit(X_train, y_train, batch_size = 128, epochs = 2, validation_split=0.1, \n",
    "                        verbose = 1, callbacks = [check_point, early_stop])\n",
    "    model = load_model(file_path)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1, history1 = build_model1(lr = 1e-3, lr_d = 1e-10, units = 64,\\\n",
    "                      spatial_dr = 0.3, kernel_size1=3, kernel_size2=2,\\\n",
    "                      dense_units=32, dr=0.1, conv_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history1.history['accuracy'])\n",
    "plt.plot(history1.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history1.history['loss'])\n",
    "plt.plot(history1.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_3 = model1.predict(X_val)\n",
    "accuracy_score(list(map(lambda x: np.argmax(x), y_val)),\\\n",
    "               list(map(lambda x: np.argmax(x), y_hat_3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(list(map(lambda x: np.argmax(x), y_val)),\\\n",
    "                 list(map(lambda x: np.argmax(x), y_hat_3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer(np.array([[s] for s in ['amazing', 'thrilling experience', 'expected more', 'it was fun', 'waste of time']])).numpy()\n",
    "y_test = model1.predict(X_test)\n",
    "[(i+1, list(y).index(max(y))) for i, y in enumerate(y_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer(np.array([[s] for s in df_test['Text'].values])).numpy()\n",
    "y_test = model1.predict(X_test)\n",
    "y_test_class = [list(y).index(max(y)) for i, y in enumerate(y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_sub = '..\\\\input\\\\movie-review-sentiment-analysis-kernels-only\\\\sampleSubmission.csv'\n",
    "df_sub = pd.read_csv(data_file_sub)\n",
    "df_sub['Sentiment'] = np.asarray(y_test_class)\n",
    "df_sub.to_csv(\"bigru_lstm.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
