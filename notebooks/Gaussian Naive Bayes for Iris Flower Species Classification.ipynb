{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"orange\">Gaussian Naive Bayes for Iris Flower Species Classification</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd #input\n",
    "from numpy.random import rand\n",
    "from numpy import mean, std #mean and standard deviation for gaussian probabilities\n",
    "from scipy.stats import norm #gaussian probabilities\n",
    "from math import log # to calculate posterior probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_colname = 'class'\n",
    "train_ds_percent = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iris Flower Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_data = '../input/iris-species/Iris.csv'\n",
    "f_cols = ['SepalLengthCm',  'SepalWidthCm',  'PetalLengthCm',  'PetalWidthCm', 'Species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine Learning Mastery\n",
    "url: https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/\n",
    "<img src=\"../assets/images/MLMastery-GaussianNB.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f_data = '../input/ml_mastery/MLMastery-GaussianNB.csv'\n",
    "f_cols = ['X1', 'X2', 'Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the csv file\n",
    "df = pd.read_csv(f_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### drop unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unwanted columns\n",
    "drop_cols = list(set(df.columns) - set(f_cols))\n",
    "df = df.drop(drop_cols, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rename last column that supposedly has a class/label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the last column to 'class'\n",
    "cols = df.columns.to_list()\n",
    "cols[len(cols)-1] = class_colname\n",
    "df.columns = cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check for data getting loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm        class\n",
      "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
      "1            4.9           3.0            1.4           0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    return\n",
    "            classes: (list) of unique class names in the dataset,\n",
    "             got from the last column named class_colname.\n",
    "             \n",
    "            features: (list) of features (column names) in the dataset.\n",
    "             this excludes the last column which we expect it to have the class labels.\n",
    "             \n",
    "            prior: (1-d array) of dim num_classes\n",
    "            (prior probability of a set of features belonging to a class)\n",
    "            \n",
    "            mean_std: (3-d array) of dim num_classes x num_features x 2 (2: mean and std)\n",
    "            (mean and standard deviation for all features, given the class)\n",
    "            \n",
    "    arguments:\n",
    "    df: (dataframe) with features and class names (should have a 'class' column in addition to the feature columns).\n",
    "    class_colname: (string) provide suitable column name otherwise, using the class_colname argument.\n",
    "'''\n",
    "def train_gaussian_nb(df, class_colname='class'):\n",
    "    #number of classes\n",
    "    classes = df[class_colname].unique()\n",
    "    num_classes = len(df[class_colname].unique())\n",
    "    #number of features\n",
    "    features = df.columns[:-1]\n",
    "    num_features = len(features)\n",
    "    #number of data points\n",
    "    N = len(df)\n",
    "    \n",
    "    #data structures for priors and\n",
    "    # (mean, standard deviation) pairs for each feature and class\n",
    "    # to later calculate likelihood (conditional probability of feature given class)\n",
    "    prior = np.zeros(num_classes)\n",
    "    mean_std = np.zeros((num_classes, num_features, 2), dtype=float)\n",
    "    \n",
    "    #for each class...\n",
    "    for cls in range(num_classes):\n",
    "        #calculate prior probability of data point belonging to class cls\n",
    "        prior[cls] = len(df[df[class_colname]==classes[cls]]) / N\n",
    "\n",
    "        #to later calculate likelihood: conditional probability for all features, given class cls,\n",
    "        #we store the mean and standard deviation of all features, given class cls\n",
    "        for i_feature in range(num_features):\n",
    "            #store mean for i_feature, given cls\n",
    "            mean_std[cls][i_feature][0] = mean(df[df[class_colname]==classes[cls]].iloc[:, i_feature])\n",
    "            #store standard deviation for i_feature, given cls\n",
    "            mean_std[cls][i_feature][1] = std(df[df[class_colname]==classes[cls]].iloc[:, i_feature])\n",
    "            \n",
    "    return classes, features, prior, mean_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    return (integer) the (0-based) index of class to which the document belongs\n",
    "    \n",
    "    arguments:\n",
    "    num_classes: (int) number of classes\n",
    "    num_features: (int) number of features\n",
    "    prior: (1-d array) of dim num_classes\n",
    "           (prior probability of a set of features belonging to a class)\n",
    "    mean_std: (3-d array) of dim num_classes x num_features x 2 (2: mean and std)\n",
    "              (mean and standard deviation for all features, given the class)\n",
    "    x: (list) of features\n",
    "'''\n",
    "def apply_gaussian_naive_bayes(num_classes, num_features, prior, mean_std, x):\n",
    "    score = np.zeros((num_classes), dtype=float)\n",
    "    \n",
    "    #for each class...\n",
    "    for cls in range(num_classes):\n",
    "        #print('class:', cls)\n",
    "        \n",
    "        #for this class, add the log-prior probability to the score\n",
    "        score[cls] += log(prior[cls], 10) #log to the base 10\n",
    "        \n",
    "        #for each feature, add the log-likelihood to the score\n",
    "        for i_feature in range(num_features):\n",
    "            #print('feature', i_feature)\n",
    "            #calculate likelihood from the trained mean and standard deviation\n",
    "            mu = mean_std[cls][i_feature][0]\n",
    "            sigma = mean_std[cls][i_feature][1]\n",
    "            likelihood = norm(mu, sigma).pdf(x[i_feature])\n",
    "            #add the log-likelihood to the score\n",
    "            score[cls] += log(likelihood, 10) #log to the base 10\n",
    "    \n",
    "    #return the index of class with the maximum-a-posterior probability\n",
    "    return score.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### split dataset into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask a % of data for training, and the remaining for testing\n",
    "mask = rand(len(df)) < train_ds_percent\n",
    "df_train = df[mask]\n",
    "df_test = df[~mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the prior and likelihood on observed data df_train\n",
    "classes, features, prior, mean_std = train_gaussian_nb(df_train, class_colname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:  28 Incorrect:  1\n",
      "Percentage of correct predictions:  96.55172413793103\n"
     ]
    }
   ],
   "source": [
    "#iterate over test dataset and count the number of correct and incorrect predictions\n",
    "count_correct, count_incorrect = 0, 0\n",
    "for index, row in df_test.iterrows():\n",
    "    #actual class\n",
    "    actual_cls = row[class_colname]\n",
    "    #predicted class\n",
    "    # input provided as row[:-1].to_list(), means, all columns except last, converted to a list\n",
    "    pred_cls = apply_gaussian_naive_bayes(len(classes), len(features), prior, mean_std, row[:-1].to_list())\n",
    "    if classes[pred_cls] == actual_cls:\n",
    "        count_correct += 1\n",
    "    else:\n",
    "        count_incorrect += 1\n",
    "    #print('(predicted, actual):', classes[pred_cls], row[class_colname])\n",
    "print('Correct: ', count_correct, 'Incorrect: ', count_incorrect)\n",
    "print('Percentage of correct predictions: ', (count_correct * 100)/(count_correct + count_incorrect))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
